<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>

<head>
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <style type="text/css">
  /* Design Credits: Jon Barron, Deepak Pathak, Saurabh Gupta and Aditya Kusupati*/
  a {
  color: #1772d0;
  text-decoration:none;
  }
  a:focus, a:hover {
  color: #f09228;
  text-decoration:none;
  }
  body,td,th {
     font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
     font-size: 16px;
     font-weight: 400
  }
  heading {
     font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
     font-size: 19px;
     font-weight: 1000
  }
  strong {
     font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
     font-size: 16px;
     font-weight: 800
  }
  strongred {
     font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
     color: 'red' ;
     font-size: 16px
  }
  sectionheading {
     font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
     font-size: 22px;
     font-weight: 600
  }
  pageheading {
     font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
     font-size: 38px;
     font-weight: 400
  }
  </style>
  <!-- <link rel="icon" type="image/png" href="images/W.png"> -->
  <script type="text/javascript" src="js/hidebib.js"></script>
  <title>Ranajoy Sadhukhan</title>
  <meta name="Ranajoy Sadhukhan's Homepage" http-equiv="Content-Type" content="Ranajoy Sadhukhan's Homepage">
  <link href='https://fonts.googleapis.com/css?family=Titillium+Web:400,600,400italic,600italic,300,300italic' rel='stylesheet' type='text/css'>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">

  <!-- Scramble Script by Jeff Donahue -->
  <script src="js/scramble.js"></script>
</head>

<body>
<table width="840" border="0" align="center" border="0" cellspacing="0" cellpadding="20">
  <tr><td>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
  <p align="center">
     <pageheading>Ranajoy Sadhukhan</pageheading><br>
     <b>email</b>:
     <font id="email" style="display:inline;">
        <noscript><i>Please enable Javascript to view</i></noscript>
     </font>
     <script>
     emailScramble = new scrambledString(document.getElementById('email'),
          'emailScramble', 'rsadhukhan900@gmail.com',
          [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23]);
     </script>
  </p>

  <tr>
     <td width="32%" valign="top"><a href="#Bio"><img src="images/portrait.png" width="100%" style="border-radius:15px"></a>
     <p align=center>
     <a href="pubs/CV.pdf" target="_blank">CV</a> | <a href="https://scholar.google.com/citations?hl=en&user=okWY7CwAAAAJ" target="_blank">Scholar</a> | <a href="https://github.com/ranonrkm" target="_blank">Github</a><br>
     </p>
     </td>
     <td width="68%" valign="top" align="justify" id="Bio">
     <p> I am a Research Fellow at Microsoft Research India. I am fortunate to be advised by <a href="https://harsha-simhadri.org/" target="_blank">Dr. Harsha Vardhan Simhadri</a> and <a href="https://www.microsoft.com/en-us/research/people/rakri/" target="_blank">Dr. Manik Varma</a>.</p>
     <p> My current research interests include efficient and robust solutions for large-scale retrieval and recommendation system. In particular, I am working on memory-efficient and low-latency approximate nearest neighbor search methods (<a href="https://github.com/microsoft/DiskANN" target="_blank">DiskANN</a>). Additionally, I collaborate with the <a href="https://www.microsoft.com/en-us/research/project/extreme-classification/" target="_blank">Extreme Classification</a> team.</p>
     <p> Prior to joining MSR, I graduated from the Indian Institute of Technology Kharagpur with a dual degree (5 yr B. Tech. + M. Tech.) in Electrical Engineering and a minor in Computer Science Engineering. At IIT Kharagpur, I had the privilege of working with <a href="http://www.facweb.iitkgp.ac.in/~jay/" target="_blank">Dr. Jayanta Mukhopadhyay</a> on my thesis projects focused on interpretable and robust model optimization for image classification.</p>
     </td>
  </tr>
</table>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
  <tr><td id="Publications"> <sectionheading>&nbsp;&nbsp;Publications</sectionheading></td></tr>
</table>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
  <tr>
     <td width="33%" valign="top" align="center"><a href="https://ieeexplore.ieee.org/document/9898007" target="_blank"><img src="images/HSD.png" alt="HSD-CNN" width="100%" style="border-radius:15px"></a>
     <td width="67%" valign="top">
        <p><a href="https://ieeexplore.ieee.org/document/9898007" target="_blank">
        <heading>Taxonomy Driven Learning Of Semantic Hierarchy Of Classes</heading></a><br>
        <strong>Ranajoy Sadhukhan</strong>, Ankita Chatterjee, Jayanta Mukhopadhyay, Amit Patra</a> <br>
        IEEE International Conference on Image Processing (<strong>ICIP</strong>), 2022<br>
        </p>

        <div class="paper" id="hsdcnn">
        <a href="javascript:toggleblock('hsdcnnabs')">abstract</a> / 
        <a shape="rect" href="javascript:togglebib('hsdcnn')" class="togglebib">bibtex</a> / 
        <a href="https://ieeexplore.ieee.org/document/9898007" target="_blank">paper</a>
        <br>

        <p align="justify"> <i id="hsdcnnabs">Standard pre-trained convolutional neural networks are deployed on different task-specific limited class applications. These applications require classifying images of a much smaller subset of classes than that of the original large domain dataset on which the network is pre-trained. Therefore, a computationally inefficient and over-represented network is obtained. Hierarchically Self Decomposing CNN (HSD-CNN) addresses this issue by dissecting the network into sub-networks in an automated hierarchical fashion such that each sub-network is useful for classifying images of closely related classes. However, visual similarities are not always well-aligned with the semantic understanding of humans. In this paper, we propose a method that aids the pre-trained network to learn the hierarchy of classes derived from standard taxonomy, WordNet and, produce sub-networks corresponding to semantically meaningful classes upon decomposition. Experimental results show that the cluster of classes obtained for each sub-network is semantically closer according to WordNet hierarchy without degradation in overall accuracy.</i></p>

<pre xml:space="preserve">
@INPROCEEDINGS{9898007,
  author={Sadhukhan, Ranajoy and Chatterjee, Ankita and Mukhopadhyay, Jayanta and Patra, Amit},
  booktitle={2022 IEEE International Conference on Image Processing (ICIP)}, 
  title={Taxonomy Driven Learning Of Semantic Hierarchy Of Classes}, 
  year={2022},
  volume={},
  number={},
  pages={171-175},
  doi={10.1109/ICIP46576.2022.9898007}}
}</pre>
        </div>
      </td>
  </tr>
</table>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
  <tr>
     <td width="33%" valign="top" align="center"><a href="https://ieeexplore.ieee.org/document/9190672" target="_blank"><img src="images/TuckerDecomp.png" alt="kdtucker" width="100%" style="border-radius:15px"></a>
     <td width="67%" valign="top">
        <p><a href="https://ieeexplore.ieee.org/document/9190672" target="_blank">
        <heading>Knowledge Distillation Inspired Fine-Tuning Of Tucker Decomposed CNNS and Adversarial Robustness Analysis</heading></a><br>
        <strong>Ranajoy Sadhukhan</strong>, Avinab Saha, Jayanta Mukhopadhyay, Amit Patra <br>
        IEEE International Conference on Image Processing (<strong>ICIP</strong>), 2020<br>
        </p>

        <div class="paper" id="kdtucker">
        <a href="javascript:toggleblock('kdtuckerabs')">abstract</a> / 
        <a shape="rect" href="javascript:togglebib('kdtucker')" class="togglebib">bibtex</a> / 
        <a href="https://ieeexplore.ieee.org/document/9190672" target="_blank">paper</a>
        <br>

        <p align="justify"> <i id="kdtuckerabs">The recent works in Tensor decomposition of Convolutional Neural Networks have paid little attention to fine-tuning the decomposed models more effectively. We propose to improve the accuracy as well as the adversarial robustness of decomposed networks over existing non-iterative methods by distilling knowledge from the computationally intensive undecomposed(Teacher) model to the decomposed(Student) model. Through a series of experiments, we demonstrate the effectiveness of Knowledge Distillation with different loss functions and compare it to the existing fine-tuning strategy of minimizing Cross-Entropy loss with ground truth labels. Finally, we conclude that the Student networks obtained by the proposed approach are superior not only in terms of accuracy but also adversarial robustness, which is often compromised in the existing methods.</i></p>

<pre xml:space="preserve">
@INPROCEEDINGS{9190672,
  author={Sadhukhan, Ranajoy and Saha, Avinab and Mukhopadhyay, Jayanta and Patra, Amit},
  booktitle={2020 IEEE International Conference on Image Processing (ICIP)}, 
  title={Knowledge Distillation Inspired Fine-Tuning Of Tucker Decomposed CNNS and Adversarial Robustness Analysis}, 
  year={2020},
  volume={},
  number={},
  pages={1876-1880},
  doi={10.1109/ICIP40778.2020.9190672}}
}</pre>
        </div>
      </td>
  </tr>
</table>


<!-- <a href="https://info.flagcounter.com/Bdj6"><img src="https://s05.flagcounter.com/countxl/Bdj6/bg_FFFFFF/txt_000000/border_CCCCCC/columns_4/maxflags_12/viewers_0/labels_0/pageviews_1/flags_0/percent_0/" alt="Flag Counter" border="0"></a> -->

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
     <tr><td><br><p align="right"><font size="2">
     Template: <a href="https://jonbarron.info">this</a>, <a href="https://people.eecs.berkeley.edu/~pathak/">this</a>, <a href="http://saurabhg.web.illinois.edu/">this</a> and <a href="https://homes.cs.washington.edu/~kusupati/">this</a>
     </font></p></td></tr>
</table>


  </td></tr>
</table>
<script xml:space="preserve" language="JavaScript">
hideallbibs();
</script>
<script xml:space="preserve" language="JavaScript">
hideblock('hsdcnn');
</script>
<script xml:space="preserve" language="JavaScript">
hideblock('kdtucker');
</script>
</body>

</html>